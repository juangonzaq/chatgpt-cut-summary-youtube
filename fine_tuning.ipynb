{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juangonzaq/chatgpt-cut-summary-youtube/blob/main/fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrena tu propio modelo de GPT 3 \n",
        "## Por Álex Goia \n",
        "### @alexgoiadev\n",
        "Documentación oficial: https://platform.openai.com/docs/guides/fine-tuning/customize-your-model-name\n",
        "\n",
        "😀\n",
        "RESUMEN DE LOS PASOS PREVIOS:\n",
        "1.   Tener una cuenta abierta en OpenaAI\n",
        "2.   Generar una api key dentro de OpenAI\n",
        "3.   Crear un Google Sheet o Excel con la columna **prompt** y **completion**\n",
        "    1. En el prompt ponemos el texto que escribiremos y mandaremos al modelo\n",
        "    2. En el completion la respuesta que deseamos para ese conexto y un patrón de finalización. En mi ejemplo verás _END esto ayuda para que el aprendizaje tenga claro el final del completion.\n",
        "    3. Lo ideal es hacer más de 200 muestras para que el entrenamiento preciso. En teoría cuanto más mejor. \n",
        "    4. Exportar a .csv\n",
        "4. Subir el archivo .csv aquí o a google drive\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5tlmTljM3izG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Damos permiso a Google Drive (opcional)\n",
        "Si queremos acceder directamente a los datos de Google drive podeis hacerlo. Sino subid manualmente el archivo data.csv. ¿Por qué no importa? Porque openai subirá vuestro archivo a sus servidores y el modelo quedará registrado en su plataforma y asociado a vuestra cuenta."
      ],
      "metadata": {
        "id": "cYE_Fpo9Ivbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrdUT80AIuEK",
        "outputId": "bfe87737-9f26-41e3-cfd2-661ff6f4d690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dRn_ndJP3efz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Instalamos OpenAI"
      ],
      "metadata": {
        "id": "ATMR7e017TEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.27.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca916-MW6yMj",
        "outputId": "b1e024d2-1f92-450b-8312-a780301dd64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai==0.27.0\n",
            "  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai==0.27.0) (2.25.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai==0.27.0) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai==0.27.0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai==0.27.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai==0.27.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai==0.27.0) (2022.12.7)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai==0.27.0) (22.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, charset-normalizer, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.0 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Añadimos nuestro API KEY como variable de Entorno\n"
      ],
      "metadata": {
        "id": "YOJtKdY07XPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "api_key = \"\" #@param {type:\"string\"}\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n"
      ],
      "metadata": {
        "id": "m_o730Gc7RtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparamos el archivo\n",
        "1. Sube el archivo .csv \n",
        "2. Pincha en botón derecho\n",
        "3. Copiar ruta\n",
        "4. Pégalo en file_path"
      ],
      "metadata": {
        "id": "pNfLw2EiKspX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_path = \"/content/data.csv\" #@param {type:\"string\"}\n",
        "os.environ[\"FILE_PATH\"] = file_path\n",
        "\n",
        "!openai tools fine_tunes.prepare_data -f $file_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEGFK8WUJ6an",
        "outputId": "7f4b4bb3-5676-4096-f6bb-0bdace391c13",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Based on your file extension, your file is formatted as a CSV file\n",
            "- Your file contains 120 prompt-completion pairs\n",
            "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
            "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
            "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
            "- More than a third of your `prompt` column/key is uppercase. Uppercase prompts tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "- More than a third of your `completion` column/key is uppercase. Uppercase completions tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
            "- [Recommended] Lowercase all your data in column/key `prompt` [Y/n]: n\n",
            "- [Recommended] Lowercase all your data in column/key `completion` [Y/n]: n\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: y\n",
            "- [Recommended] Would you like to split into training and validation set? [Y/n]: n\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: y\n",
            "\n",
            "Wrote modified file to `/content/data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/data_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"O _END\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 5.21 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrena con el modelo\n",
        "**model_sufix** se refiere a un sufijo que quieras añadirle a tu modelo para que luego lo puedas identificar con facilidad.\n",
        "**selecion**: \"davinci\", \"curie\", \"babbage\", \"ada\" \n"
      ],
      "metadata": {
        "id": "Yu6Sho3ontbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sufix = \"trend-youtube-demo\" #@param {type:\"string\"}\n",
        "selection = \"davinci\" #@param {type:\"string\"}\n",
        "!openai api fine_tunes.create -t /content/data_prepared.jsonl -m $selection --suffix $model_sufix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f59a71-4589-4a3c-aa11-954ce183fd78",
        "id": "uYghKQpXqZIk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found potentially duplicated files with name 'data_prepared.jsonl', purpose 'fine-tune' and size 14116 bytes\n",
            "file-bLiXbPmoQzlJ9FDzKmTLhjUi\n",
            "file-72zQsGbs7XIb2810aj3zRt2A\n",
            "file-WWkwXox5KYZmS0pehxu52P6i\n",
            "file-Tnz5nnuU0E1o5cyZZawc7dIX\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "Upload progress: 100% 14.1k/14.1k [00:00<00:00, 17.0Mit/s]\n",
            "Uploaded file from /content/data_prepared.jsonl: file-4TY9Hi4W9mR0yMEi2k5aKggL\n",
            "Created fine-tune: ft-M2aXFvpOlKtIbXcC1fs7MwSU\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-02-10 18:57:03] Created fine-tune: ft-M2aXFvpOlKtIbXcC1fs7MwSU\n",
            "\n",
            "Stream interrupted. Job is still pending.\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-M2aXFvpOlKtIbXcC1fs7MwSU\n",
            "\n",
            "To cancel your job, run:\n",
            "\n",
            "  openai api fine_tunes.cancel -i ft-M2aXFvpOlKtIbXcC1fs7MwSU\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigue el resultado del aprendizaje\n"
      ],
      "metadata": {
        "id": "4-gWgybgskrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"ft-M2aXFvpOlKtIbXcC1fs7MwSU\" #@param {type:\"string\"}\n",
        "!openai api fine_tunes.follow -i $model_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic2yAXcFsnlb",
        "outputId": "ffb3e04a-b82e-4353-b269-b6e2f62bb529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-02-10 01:01:20] Created fine-tune: ft-AyZOtwhToMIPTT3agE5endvu\n",
            "[2023-02-10 02:01:10] Fine-tune costs $0.46\n",
            "[2023-02-10 02:01:10] Fine-tune enqueued. Queue number: 25\n",
            "[2023-02-10 02:01:15] Fine-tune is in the queue. Queue number: 24\n",
            "[2023-02-10 02:01:16] Fine-tune is in the queue. Queue number: 23\n",
            "[2023-02-10 02:01:19] Fine-tune is in the queue. Queue number: 22\n",
            "[2023-02-10 02:02:19] Fine-tune is in the queue. Queue number: 21\n",
            "[2023-02-10 02:03:16] Fine-tune is in the queue. Queue number: 20\n",
            "[2023-02-10 02:05:59] Fine-tune is in the queue. Queue number: 19\n",
            "[2023-02-10 02:07:43] Fine-tune is in the queue. Queue number: 18\n",
            "[2023-02-10 02:08:03] Fine-tune is in the queue. Queue number: 17\n",
            "[2023-02-10 02:08:18] Fine-tune is in the queue. Queue number: 16\n",
            "[2023-02-10 02:12:39] Fine-tune is in the queue. Queue number: 15\n",
            "[2023-02-10 02:15:10] Fine-tune is in the queue. Queue number: 14\n",
            "[2023-02-10 02:16:05] Fine-tune is in the queue. Queue number: 13\n",
            "[2023-02-10 02:18:00] Fine-tune is in the queue. Queue number: 12\n",
            "[2023-02-10 02:18:02] Fine-tune is in the queue. Queue number: 11\n",
            "[2023-02-10 02:21:11] Fine-tune is in the queue. Queue number: 10\n",
            "[2023-02-10 02:29:12] Fine-tune is in the queue. Queue number: 9\n",
            "[2023-02-10 02:35:36] Fine-tune is in the queue. Queue number: 8\n",
            "[2023-02-10 02:36:12] Fine-tune is in the queue. Queue number: 7\n",
            "[2023-02-10 02:39:15] Fine-tune is in the queue. Queue number: 6\n",
            "[2023-02-10 02:39:46] Fine-tune is in the queue. Queue number: 5\n",
            "[2023-02-10 02:40:13] Fine-tune is in the queue. Queue number: 4\n",
            "[2023-02-10 02:40:48] Fine-tune is in the queue. Queue number: 3\n",
            "[2023-02-10 02:41:23] Fine-tune is in the queue. Queue number: 2\n",
            "[2023-02-10 02:42:07] Fine-tune is in the queue. Queue number: 1\n",
            "[2023-02-10 02:42:13] Fine-tune is in the queue. Queue number: 0\n",
            "[2023-02-10 02:42:56] Fine-tune started\n",
            "[2023-02-10 02:45:18] Completed epoch 1/4\n",
            "[2023-02-10 02:45:53] Completed epoch 2/4\n",
            "[2023-02-10 02:46:28] Completed epoch 3/4\n",
            "[2023-02-10 02:47:04] Completed epoch 4/4\n",
            "[2023-02-10 02:47:42] Uploaded model: davinci:ft-personal:trend-youtube-2023-02-10-02-47-41\n",
            "[2023-02-10 02:47:43] Uploaded result file: file-nNBz0GSvuw3qvVhJ7fVsuYIg\n",
            "[2023-02-10 02:47:43] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-personal:trend-youtube-2023-02-10-02-47-41 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Crea TU PROPIO MODELO DE IA GPT3 sin saber PROGRAMAR ->\" #@param {type:\"string\"}\n",
        "\n",
        "!openai api completions.create -m davinci:ft-personal:trend-youtube-2023-02-10-02-47-41 -p $prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FhloELZTKux",
        "outputId": "bad8f374-7b36-404d-8e69-93982f334796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: `openai api completions.create -m davinci:ft-personal:trend-youtube-2023-02-10-02-47-41 -p Crea TU PROPIO MODELO DE IA GPT3 sin saber PROGRAMAR ->'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cancelar un entrenamiento\n"
      ],
      "metadata": {
        "id": "y8x-s18y0scw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"ft-rBsYr1bbBemg8JCwxaeaJ61p\" #@param {type:\"string\"}\n",
        "!openai api fine_tunes.cancel -i $model_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtKJHyLT0ynB",
        "outputId": "031bfc26-2cc0-43ef-9f9d-c83c96cb4ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"created_at\": 1675988507,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"created_at\": 1675988507,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-rBsYr1bbBemg8JCwxaeaJ61p\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1675990678,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune cancelled\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    }\n",
            "  ],\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"hyperparams\": {\n",
            "    \"batch_size\": null,\n",
            "    \"learning_rate_multiplier\": null,\n",
            "    \"n_epochs\": 4,\n",
            "    \"prompt_loss_weight\": 0.01\n",
            "  },\n",
            "  \"id\": \"ft-rBsYr1bbBemg8JCwxaeaJ61p\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"organization_id\": \"org-bZrkCtLdLMNsZVNlLtvw8ZVe\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"cancelled\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"bytes\": 14116,\n",
            "      \"created_at\": 1675988507,\n",
            "      \"filename\": \"/content/data_prepared.jsonl\",\n",
            "      \"id\": \"file-WWkwXox5KYZmS0pehxu52P6i\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"updated_at\": 1675990678,\n",
            "  \"validation_files\": []\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}